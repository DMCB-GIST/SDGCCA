{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e76a862",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d4cc226",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from utils import *\n",
    "from SDGCCA import SDGCCA_3_M\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901526b5",
   "metadata": {},
   "source": [
    "### Seed fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a1bce98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed Setting\n",
    "random_seed = 100\n",
    "set_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143ad12c",
   "metadata": {},
   "source": [
    "### Train SDGCCA\n",
    "\n",
    "**Toy Dataset**  \n",
    "- Label: Binary\n",
    "- Modality1: n(376) x d1 (18164)\n",
    "- Modality1: n(376) x d2 (19353)\n",
    "- Modality1: n(376) x d3 (309)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "223b6663",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SDGCCA(hyper_dict):\n",
    "    # Return List\n",
    "    ensemble_list = {'ACC': [], 'F1': [], 'AUC': [], 'MCC': []}\n",
    "    metric_list = ['ACC', 'F1', 'AUC', 'MCC']\n",
    "    hyper_param_list = []\n",
    "    best_hyper_param_list = []\n",
    "    \n",
    "    # Prepare Toy Dataset\n",
    "    dataset = Toy_Dataset(hyper_dict['random_seed'])\n",
    "\n",
    "    # 5 CV\n",
    "    for cv in tqdm(range(5), desc='CV...'):\n",
    "        # Prepare Dataset\n",
    "        [x_train_1, x_val_1, x_test_1], [x_train_2, x_val_2, x_test_2], [x_train_3, x_val_3, x_test_3], \\\n",
    "        [y_train, y_val, y_test] = dataset(cv, tensor=True, device=hyper_dict['device'])\n",
    "        \n",
    "        # Define Deep neural network dimension of the each modality\n",
    "        m1_embedding_list = [x_train_1.shape[1]] + hyper_dict['embedding_size']\n",
    "        m2_embedding_list = [x_train_2.shape[1]] + hyper_dict['embedding_size']\n",
    "        m3_embedding_list = [x_train_3.shape[1]] + hyper_dict['embedding_size'][1:]\n",
    "\n",
    "        # Train Label -> One_Hot_Encoding\n",
    "        y_train_onehot = torch.zeros(y_train.shape[0], 2).float().to(hyper_dict['device'])\n",
    "        y_train_onehot[range(y_train.shape[0]), y_train.squeeze()] = 1\n",
    "\n",
    "        # Find Best K by Validation MCC\n",
    "        val_mcc_result_list = []\n",
    "        test_ensemble_dict = {'ACC': [], 'F1': [], 'AUC': [], 'MCC': []}\n",
    "\n",
    "        # Grid search for find best hyperparameter by Validation MCC\n",
    "        for top_k in tqdm(range(1, hyper_dict['max_top_k']+1), desc='Grid seach for find best hyperparameter...'):\n",
    "            for lr in hyper_dict['lr']:\n",
    "                for reg in hyper_dict['reg']:\n",
    "                    hyper_param_list.append([top_k, lr, reg])\n",
    "                    early_stopping = EarlyStopping(patience=hyper_dict['patience'], delta=hyper_dict['delta'])\n",
    "                    best_loss = np.Inf\n",
    "\n",
    "                    # Define SDGCCA with 3 modality\n",
    "                    model = SDGCCA_3_M(m1_embedding_list, m2_embedding_list, m3_embedding_list, top_k).to(hyper_dict['device'])\n",
    "\n",
    "                    # Optimizer\n",
    "                    clf_optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=reg)\n",
    "\n",
    "                    # Cross Entropy Loss\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "                    # Model Train\n",
    "                    for i in range(hyper_dict['epoch']):\n",
    "                        model.train()\n",
    "\n",
    "                        # Calculate correlation loss\n",
    "                        out1, out2, out3 = model(x_train_1, x_train_2, x_train_3)\n",
    "                        cor_loss = model.cal_loss([out1, out2, out3, y_train_onehot])\n",
    "\n",
    "                        # Calculate classification loss\n",
    "                        clf_optimizer.zero_grad()\n",
    "\n",
    "                        y_hat1, y_hat2, y_hat3, _ = model.predict(x_train_1, x_train_2, x_train_3)\n",
    "                        clf_loss1 = criterion(y_hat1, y_train.squeeze())\n",
    "                        clf_loss2 = criterion(y_hat2, y_train.squeeze())\n",
    "                        clf_loss3 = criterion(y_hat3, y_train.squeeze())\n",
    "\n",
    "                        clf_loss = clf_loss1 + clf_loss2 + clf_loss3\n",
    "\n",
    "                        clf_loss.backward()\n",
    "                        clf_optimizer.step()\n",
    "\n",
    "                        # Model Validation\n",
    "                        with torch.no_grad():\n",
    "                            model.eval()\n",
    "                            _, _, _, y_ensemble = model.predict(x_val_1, x_val_2, x_val_3)\n",
    "                            val_loss = criterion(y_ensemble, y_val.squeeze())\n",
    "\n",
    "                            early_stopping(val_loss)\n",
    "                            if val_loss < best_loss:\n",
    "                                best_loss = val_loss\n",
    "\n",
    "                            if early_stopping.early_stop:\n",
    "                                break\n",
    "\n",
    "                    # Load Best Model\n",
    "                    model.eval()\n",
    "\n",
    "                    # Model Validation\n",
    "                    _, _, _, ensembel_y_hat = model.predict(x_val_1, x_val_2, x_val_3)\n",
    "                    y_pred_ensemble = torch.argmax(ensembel_y_hat, 1).cpu().detach().numpy()\n",
    "                    y_pred_proba_ensemble = ensembel_y_hat[:, 1].cpu().detach().numpy()            \n",
    "                    _, _, _, val_mcc = calculate_metric(y_val.cpu().detach().numpy(), y_pred_ensemble, y_pred_proba_ensemble)\n",
    "                    val_mcc_result_list.append(val_mcc)\n",
    "\n",
    "                    # Model Tset\n",
    "                    _, _, _, ensembel_y_hat = model.predict(x_test_1, x_test_2, x_test_3)\n",
    "                    y_pred_ensemble = torch.argmax(ensembel_y_hat, 1).cpu().detach().numpy()\n",
    "                    y_pred_proba_ensemble = ensembel_y_hat[:, 1].cpu().detach().numpy()\n",
    "                    test_acc, test_f1, test_auc, test_mcc = calculate_metric(y_test.cpu().detach().numpy(), y_pred_ensemble, y_pred_proba_ensemble)\n",
    "                    ensemble_result = [test_acc, test_f1, test_auc, test_mcc]\n",
    "                    for k, metric in enumerate(metric_list):\n",
    "                        test_ensemble_dict[metric].append(ensemble_result[k])\n",
    "\n",
    "        # Find best K\n",
    "        best_k = np.argmax(val_mcc_result_list)\n",
    "        \n",
    "        # Find best hyperparameter\n",
    "        best_hyper_param_list.append(hyper_param_list[best_k])\n",
    "        \n",
    "        # Append Best K Test Result\n",
    "        for metric in metric_list:\n",
    "            ensemble_list[metric].append(test_ensemble_dict[metric][best_k])\n",
    "\n",
    "    return ensemble_list, best_hyper_param_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f022d894",
   "metadata": {},
   "source": [
    "### Setting Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee055f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_dict = {'epoch': 1000, 'delta': 0, 'random_seed': random_seed,\n",
    "              'device': torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\"),\n",
    "              'lr': [0.0001,0.00001], 'reg': [0, 0.01,0.0001], \n",
    "              'patience': 30, 'embedding_size': [256, 64, 16], 'max_top_k': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537d2586",
   "metadata": {},
   "source": [
    "### Model Training & Check Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5bcfbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423e92fec0c14924ac5d9109123e49e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CV...:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436ce2731b124f8da928105f5e050b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid seach for find best hyperparameter...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d71effb8624be28590b1ea1b2274ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid seach for find best hyperparameter...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2a684f369a4e9d9ffda2bbc93e8db1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid seach for find best hyperparameter...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd46b84d739f4c56bbe11a1d2bb3f2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid seach for find best hyperparameter...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c494abfaf041088646137ddc0189fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Grid seach for find best hyperparameter...:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Performance\n",
      "ACC: 50.27+-2.58 F1: 38.35+-10.52 AUC: 48.03+-3.45 MCC: -0.96+-5.80\n",
      "\n",
      "Best Hyperparameter\n",
      "CV: 1 Best k: 5 Learning Rage: 1e-05 Regularization Term: 0.0001\n",
      "CV: 2 Best k: 4 Learning Rage: 1e-05 Regularization Term: 0\n",
      "CV: 3 Best k: 2 Learning Rage: 1e-05 Regularization Term: 0.01\n",
      "CV: 4 Best k: 8 Learning Rage: 1e-05 Regularization Term: 0.0001\n",
      "CV: 5 Best k: 4 Learning Rage: 1e-05 Regularization Term: 0\n"
     ]
    }
   ],
   "source": [
    "ensemble_list, hyper = train_SDGCCA(hyper_dict)\n",
    "\n",
    "# Check Performance\n",
    "performance_result = check_mean_std_performance(ensemble_list)\n",
    "\n",
    "print('Test Performance')\n",
    "print('ACC: {} F1: {} AUC: {} MCC: {}'.format(performance_result[0], performance_result[1], performance_result[2], performance_result[3]))\n",
    "\n",
    "print('\\nBest Hyperparameter')\n",
    "for i, h in enumerate(hyper):\n",
    "    print('CV: {} Best k: {} Learning Rage: {} Regularization Term: {}'.format(i+1, h[0], h[1], h[2]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
